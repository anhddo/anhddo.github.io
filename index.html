<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Anh D. Do</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Anh D. Do</h1>
</div>
<table class="imgtable"><tr><td>
<a href="IMGLINKTARGET"><img src="avatar.png" alt="alt text" width="150px" height="190px" /></a>&nbsp;</td>
<td align="left"><p>AI Resident &ndash; VinAI research, Hanoi, Vietnam <br />
John von Neumann Institute &ndash; VNU-HCM <br />
<b>Contact</b>: anhddo93 at gmail dot com <br />
<a href="https://github.com/anhddo">Github</a>, cv</p>
</td></tr></table>
<p><b>Research interest</b>: Multi-armed bandits, Reinforcement learning theory.</p>
<h2>Publications</h2>
<p><b>Regret bound for optimistic value iteration for average reward MDPs</b>. <br />
Yasin Abbasi-Yadkori, Anh Do, Botao Hao, Nevena Lazic, Csaba Szepesvari</p>
<h2>Activities</h2>
<p>Multi-armed bandits reading group (<a href="https://drive.google.com/drive/folders/1ocHNCCG9yjUDPwyzl_RysMyuzq3KAaHi?usp=sharing">presentation</a>, <a href="https://colab.research.google.com/drive/1gvdIiG6sKdWEHVKBUYPx-sGvwI5a0JJu?usp=sharing">code</a>). </p>
<div id="footer">
<div id="footer-text">
Page generated 2020-11-23 10:24:03 SE Asia Standard Time, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>
</body>
</html>
